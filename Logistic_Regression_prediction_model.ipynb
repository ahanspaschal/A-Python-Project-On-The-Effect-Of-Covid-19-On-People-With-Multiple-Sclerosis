{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4836838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3c16ee1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Reading data into a DataFrame\n",
    "df = pd.read_csv('GDSI_OpenDataset_Final.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea13b84c",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90e38695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_in_cat</th>\n",
       "      <th>edss_in_cat2</th>\n",
       "      <th>year_onset</th>\n",
       "      <th>covid19_outcome_levels_2</th>\n",
       "      <th>duration_treatment_cat2</th>\n",
       "      <th>comorbidities_other</th>\n",
       "      <th>secret_name_C_1006</th>\n",
       "      <th>secret_name_C_1007</th>\n",
       "      <th>secret_name_C_1008</th>\n",
       "      <th>secret_name_C_1037</th>\n",
       "      <th>...</th>\n",
       "      <th>stop_or_end_date_combined_30/10/2019</th>\n",
       "      <th>stop_or_end_date_combined_30/11/2018</th>\n",
       "      <th>stop_or_end_date_combined_30/12/2018</th>\n",
       "      <th>stop_or_end_date_combined_30/12/2019</th>\n",
       "      <th>stop_or_end_date_combined_31/01/2020</th>\n",
       "      <th>stop_or_end_date_combined_31/03/2020</th>\n",
       "      <th>stop_or_end_date_combined_31/05/2020</th>\n",
       "      <th>stop_or_end_date_combined_31/07/2019</th>\n",
       "      <th>stop_or_end_date_combined_31/10/2018</th>\n",
       "      <th>stop_or_end_date_combined_31/12/2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1510 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_in_cat  edss_in_cat2  year_onset  covid19_outcome_levels_2  \\\n",
       "0         1.0           0.0      2011.0                       0.0   \n",
       "1         1.0           0.0      2011.0                       0.0   \n",
       "2         1.0           0.0      2011.0                       0.0   \n",
       "3         1.0           0.0      2011.0                       0.0   \n",
       "4         1.0           0.0      2007.0                       1.0   \n",
       "\n",
       "   duration_treatment_cat2  comorbidities_other  secret_name_C_1006  \\\n",
       "0                      1.0                  1.0                 0.0   \n",
       "1                      1.0                  1.0                 0.0   \n",
       "2                      1.0                  1.0                 0.0   \n",
       "3                      1.0                  1.0                 0.0   \n",
       "4                      1.0                  1.0                 0.0   \n",
       "\n",
       "   secret_name_C_1007  secret_name_C_1008  secret_name_C_1037  ...  \\\n",
       "0                 0.0                 0.0                 0.0  ...   \n",
       "1                 0.0                 1.0                 0.0  ...   \n",
       "2                 0.0                 0.0                 1.0  ...   \n",
       "3                 0.0                 0.0                 0.0  ...   \n",
       "4                 0.0                 0.0                 0.0  ...   \n",
       "\n",
       "   stop_or_end_date_combined_30/10/2019  stop_or_end_date_combined_30/11/2018  \\\n",
       "0                                   0.0                                   0.0   \n",
       "1                                   0.0                                   0.0   \n",
       "2                                   0.0                                   0.0   \n",
       "3                                   0.0                                   0.0   \n",
       "4                                   0.0                                   0.0   \n",
       "\n",
       "   stop_or_end_date_combined_30/12/2018  stop_or_end_date_combined_30/12/2019  \\\n",
       "0                                   0.0                                   0.0   \n",
       "1                                   0.0                                   0.0   \n",
       "2                                   0.0                                   0.0   \n",
       "3                                   0.0                                   0.0   \n",
       "4                                   0.0                                   0.0   \n",
       "\n",
       "   stop_or_end_date_combined_31/01/2020  stop_or_end_date_combined_31/03/2020  \\\n",
       "0                                   0.0                                   0.0   \n",
       "1                                   0.0                                   0.0   \n",
       "2                                   0.0                                   0.0   \n",
       "3                                   0.0                                   0.0   \n",
       "4                                   0.0                                   0.0   \n",
       "\n",
       "   stop_or_end_date_combined_31/05/2020  stop_or_end_date_combined_31/07/2019  \\\n",
       "0                                   0.0                                   0.0   \n",
       "1                                   0.0                                   0.0   \n",
       "2                                   0.0                                   0.0   \n",
       "3                                   0.0                                   0.0   \n",
       "4                                   0.0                                   0.0   \n",
       "\n",
       "   stop_or_end_date_combined_31/10/2018  stop_or_end_date_combined_31/12/2019  \n",
       "0                                   0.0                                   0.0  \n",
       "1                                   0.0                                   0.0  \n",
       "2                                   0.0                                   0.0  \n",
       "3                                   0.0                                   0.0  \n",
       "4                                   0.0                                   0.0  \n",
       "\n",
       "[5 rows x 1510 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns that need imputation of missing values\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# initializing SimpleImputers\n",
    "numeric_imputer = SimpleImputer(strategy='median')\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Applying imputation\n",
    "df[numeric_cols] = numeric_imputer.fit_transform(df[numeric_cols])\n",
    "df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])\n",
    "\n",
    "# Encoding categorical variables using One-Hot Encoding\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')  # Drop first to avoid dummy variable trap\n",
    "categorical_encoded = encoder.fit_transform(df[categorical_cols])\n",
    "\n",
    "# Creating a new DataFrame from the encoded categories\n",
    "encoded_features = encoder.get_feature_names_out(categorical_cols)\n",
    "encoded_df = pd.DataFrame(categorical_encoded, columns=encoded_features)\n",
    "\n",
    "# Combine the numeric and encoded categorical data\n",
    "cleaned_df = pd.concat([df[numeric_cols], encoded_df], axis=1)\n",
    "\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ea1f846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00498316, 0.00360121, 0.0030884 , ..., 0.00066371, 0.00066371,\n",
       "        0.00066371]),\n",
       "          PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       " 0   2.145285 -0.020181  2.179180 -1.085207 -2.513914 -1.223392 -2.040321   \n",
       " 1   4.474103  2.354968 -0.734709 -2.579584 -4.499734 -2.856085 -2.790246   \n",
       " 2   1.724622 -0.056000  2.249355 -1.264034 -2.206684 -1.329908 -3.075933   \n",
       " 3   1.520207 -0.762623  1.138026  0.140034 -1.803928 -0.723880 -0.980825   \n",
       " 4  11.112264  5.948784  2.519901 -0.321223  2.154849 -1.017531 -4.724634   \n",
       " \n",
       "         PC8       PC9      PC10  ...    PC1055    PC1056    PC1057    PC1058  \\\n",
       " 0 -0.298320 -0.026329  1.087753  ... -0.000000  0.000000 -0.000000  0.000000   \n",
       " 1 -0.909323 -0.520713  1.089430  ... -0.236434 -0.057064  0.194976  0.275836   \n",
       " 2 -0.417155  0.043366  0.834293  ... -1.458186  0.035011  0.668714 -0.719717   \n",
       " 3  1.244246 -0.547243  0.943277  ...  0.354969  0.262245  0.211120 -0.186381   \n",
       " 4  1.355134  3.281877 -2.260481  ... -1.082742  0.514485 -1.976041 -1.088589   \n",
       " \n",
       "      PC1059    PC1060    PC1061    PC1062    PC1063    PC1064  \n",
       " 0 -0.000000 -0.000000 -0.000000 -0.000000  0.000000  0.000000  \n",
       " 1 -0.519425 -1.082193  0.145634  0.264255 -0.033963 -0.853646  \n",
       " 2  0.785004 -0.662702  1.046817 -0.083251 -1.084976  1.024365  \n",
       " 3 -0.449853 -0.260667 -0.432865  0.298331 -0.433585 -0.436852  \n",
       " 4 -0.412390  0.070717 -0.150198  0.695613 -0.442178  0.195594  \n",
       " \n",
       " [5 rows x 1064 columns])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(cleaned_df)\n",
    "\n",
    "# Initializing PCA\n",
    "pca = PCA(n_components=0.95)  # retain 95% of the variance\n",
    "principal_components = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Create a DataFrame for the principal components\n",
    "pca_df = pd.DataFrame(data=principal_components, columns=[f\"PC{i+1}\" for i in range(principal_components.shape[1])])\n",
    "\n",
    "# Explained variance\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "explained_variance_ratio, pca_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f5ed66",
   "metadata": {},
   "source": [
    "Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "986238c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the original target variable from the unmodified dataset and check its content\n",
    "original_target = data['covid19_outcome_recovered']\n",
    "original_target.value_counts()\n",
    "\n",
    "# Filter out 'not_applicable' and encode the outcomes\n",
    "filtered_target = original_target[original_target != 'not_applicable']\n",
    "encoded_target = (filtered_target == 'yes').astype(int)\n",
    "\n",
    "# Match the indices of the PCA DataFrame to the filtered target\n",
    "filtered_pca_df = pca_df.loc[filtered_target.index]\n",
    "\n",
    "# Split the data into training and testing sets with the filtered and encoded target\n",
    "X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(\n",
    "    filtered_pca_df, encoded_target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a355b52d",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d0567bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        14\n",
      "           1       0.97      1.00      0.99        36\n",
      "\n",
      "    accuracy                           0.98        50\n",
      "   macro avg       0.99      0.96      0.97        50\n",
      "weighted avg       0.98      0.98      0.98        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train the logistic regression model on the filtered data\n",
    "model_filtered = LogisticRegression(max_iter=1000)\n",
    "model_filtered.fit(X_train_filtered, y_train_filtered)\n",
    "\n",
    "# Predict on the testing set with the new model\n",
    "y_pred_filtered = model_filtered.predict(X_test_filtered)\n",
    "\n",
    "# Calculate accuracy and classification report for the new target\n",
    "accuracy_filtered = accuracy_score(y_test_filtered, y_pred_filtered)\n",
    "class_report_filtered = classification_report(y_test_filtered, y_pred_filtered)\n",
    "\n",
    "print(accuracy_filtered)\n",
    "print(class_report_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d164c38",
   "metadata": {},
   "source": [
    "Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c44482d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8674285714285714,\n",
       " 'precision': 0.8292634740003161,\n",
       " 'recall': 0.9935483870967742,\n",
       " 'f1': 0.9039078993050822}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "# Using cross_validate to get more detailed results including fit time and score time\n",
    "scoring_metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "cv_results = cross_validate(model_filtered, filtered_pca_df, encoded_target, cv=5, scoring=scoring_metrics)\n",
    "\n",
    "# Calculate average scores across all folds for each metric\n",
    "average_scores = {metric: cv_results[f'test_{metric}'].mean() for metric in scoring_metrics}\n",
    "average_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2a0cc4",
   "metadata": {},
   "source": [
    "Forecast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fbc79e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahans\\anaconda3\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ahans\\anaconda3\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('yes', array([[0.16409794, 0.83590206]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a hypothetical new data point\n",
    "# Using the mean of each principal component as a typical case\n",
    "new_data_point = np.mean(filtered_pca_df, axis=0).values.reshape(1, -1)\n",
    "\n",
    "# Predict the outcome using the logistic regression model\n",
    "predicted_outcome = model_filtered.predict(new_data_point)\n",
    "predicted_probability = model_filtered.predict_proba(new_data_point)\n",
    "\n",
    "# Mapping prediction to the outcome\n",
    "outcome_mapping = {0: \"no\", 1: \"yes\"}\n",
    "predicted_outcome_str = outcome_mapping[predicted_outcome[0]]\n",
    "\n",
    "predicted_outcome_str, predicted_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032cbae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
